{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3479b3a-0a28-44df-8017-087ae5ae2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import csv\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eb83401-fa85-4d16-b74e-2bc9b5987b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_data_from_csv(csv_reader):\n",
    "    seen_sentences = set()\n",
    "    result = []\n",
    "\n",
    "    def get_sentences(text):\n",
    "        sentences = text.split('. ')\n",
    "        if sentences and sentences[-1].endswith('.'):\n",
    "            sentences[-1] = sentences[-1][:-1]\n",
    "        return sentences\n",
    "\n",
    "    \n",
    "    next(csv_reader, None) \n",
    "\n",
    "    for row in csv_reader:\n",
    "        num = int(row[0])  \n",
    "        text = row[1]\n",
    "\n",
    "        sentences = get_sentences(text)\n",
    "        unique_sentences = []\n",
    "        for sentence in sentences:\n",
    "            if sentence not in seen_sentences:\n",
    "                seen_sentences.add(sentence)\n",
    "                unique_sentences.append(sentence)\n",
    "\n",
    "        result.append([num, unique_sentences])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e02fbf50-8fe3-4c8a-a3d4-9acc22463ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "key_words_ACO = ['atmosphere', 'carbon dioxide', 'oxygen']\n",
    "key_words_TAS = ['temperature', 'atomosphere', 'surface pressure']\n",
    "key_words_CPW = ['composition', 'phenomena', 'weather patterns']\n",
    "key_words_SGL = ['surface structures', 'geological_activities', 'landforms']\n",
    "key_words_MSF = ['mission names', 'spacecraft', 'findings']\n",
    "key_words_TPS = ['temperatures', 'atmospheric pressure', 'survival challenges']\n",
    "key_words = key_words_ACO\n",
    "def filter_atmosphere_related_sentences(data, key_words):\n",
    "    filtered_data = []\n",
    "    target_keywords = key_words\n",
    "    target_tokens = [nlp(text) for text in target_keywords] \n",
    "\n",
    "    count = 1\n",
    "    for item in data:\n",
    "        num = item[0]\n",
    "        sentences = item[1]\n",
    "        for sentence in sentences:\n",
    "            print(\"evaluating sentece no#\",count,\" ...\")\n",
    "            count += 1\n",
    "            doc = nlp(sentence)\n",
    "            found = False\n",
    "            for token in doc:\n",
    "                for target_token in target_tokens:\n",
    "                    if token.similarity(target_token) > 0.8:  \n",
    "                        filtered_data.append([num, sentence])\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    break\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89846786-e4dd-4207-8978-2631a239a35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to clean Data Sets successfully.\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"Data Sets/\"\n",
    "output_dir = \"Cleaned Data Sets_1/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".csv\"):  \n",
    "        input_file_path = os.path.join(input_dir, filename)\n",
    "        output_file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        with open(input_file_path, 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            next(csv_reader)\n",
    "            data = process_data_from_csv(csv_reader)\n",
    "\n",
    "        with open(output_file_path, 'w', newline='') as outfile:\n",
    "            csv_writer = csv.writer(outfile)\n",
    "            csv_writer.writerows(data)  \n",
    "\n",
    "print(\"Data has been written to clean Data Sets successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae397d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
